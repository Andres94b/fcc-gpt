# fcc-gpt
Large language model

This is an group of files used to create a large language model LLM using Jupyter notebook. 

To be able to use it:
Firstly, you need to download anaconda and create a virtual environment using cuda to optimize the performance of the model.
Secondly, you need to install all dependencies such as Jupyter notebook, Python, NumPy, PyTorch.
The notebook torch_examples has some torch functions used for the model.
The file bigram is a notebook that shows the working principle of a LLM using the text file of the book wizard of oz. 
The file gpt-v1 is the first version of the model. It generates the vocab.txt, a training and validation dataset and it can produce text with some mistakes.
